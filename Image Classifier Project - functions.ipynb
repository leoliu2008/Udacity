{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def transform_load_image(data_dir):\n",
    "\n",
    "    train_dir = data_dir + '/train'\n",
    "    valid_dir = data_dir + '/valid'\n",
    "    test_dir = data_dir + '/test'\n",
    "    \n",
    "    # TODO: Define your transforms for the training, validation, and testing sets\n",
    "    training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                        [0.229,0.224,0.225])\n",
    "                                         ])\n",
    "\n",
    "    validaiton_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                        [0.229,0.224,0.225])\n",
    "                                           ])\n",
    "\n",
    "\n",
    "    testing_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                        [0.229,0.224,0.225])\n",
    "                                        ])\n",
    "    \n",
    "    # TODO: Load the datasets with ImageFolder\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
    "    valid_data = datasets.ImageFolder(valid_dir, transform=validaiton_transforms)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=testing_transforms)\n",
    "    \n",
    "    # TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "    trainloaders = DataLoader(train_data, batch_size=64, shuffle = True)\n",
    "    validloaders = DataLoader(valid_data, batch_size=64,shuffle = True)\n",
    "    testloaders = DataLoader(test_data, batch_size=64, shuffle = True)\n",
    "    return trainloaders, validloaders, testloaders\n",
    "\n",
    "arch={'vgg16':25088, 'densenet121': 1024}\n",
    "\n",
    "def construct_newwork(model_type='vgg16', drop_out=0.15, hidden_layer_1=1024, hidden_layer_2=512, output_units = 102, learning_rate=0.005):\n",
    "    arch={'vgg16':25088, 'densenet121': 1024}\n",
    "\n",
    "    if model_type=='vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "    elif model_type=='densenet121':\n",
    "        model=models.densenet121(pretrained=True)\n",
    "    else:\n",
    "        print(\"the model you choose is not available, please choose vgg16 or densenet121\")\n",
    "    \n",
    "    \n",
    "    #frezze the model paratemers, as we only need to update the classifier parameter(e.g. weights for the input)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # reconstruct the classifer \n",
    "    from collections import OrderedDict\n",
    "\n",
    "    input_units = arch[model_type]\n",
    "    classifier = nn.Sequential(OrderedDict([ \n",
    "                                ('fc1',nn.Linear(input_units, hidden_layer_1)), \n",
    "                                ('relu1', nn.ReLU()),\n",
    "                                ('do1',nn.Dropout(dropout)), \n",
    "                                ('fc2', nn.Linear(hidden_layer_1,hidden_layer_2)), \n",
    "                                ('relu2', nn.ReLU()), \n",
    "                                ('do2',nn.Dropout(dropout)), \n",
    "                                ('fc3', nn.Linear(hidden_layer_2,output_units)), \n",
    "                                ('output', nn.LogSoftmax(dim=1))\n",
    "                                ]))\n",
    "\n",
    "    #replace the pre-trained model's classifier withe the self-defined one as above\n",
    "    model.classifier = classifier\n",
    "    criterion = nn.NLLLoss()\n",
    "    #only trian the classifier parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(model.classifier.parameters(),lr=learning_Rate)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device);\n",
    "    \n",
    "    return model, criterion, optimizer\n",
    "\n",
    "\n",
    "def test_network(model, criterion, optimizer, epochs=20, print_every=40, steps=0):\n",
    "    model, criterion , optimizer= construct_newwork()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to (device)\n",
    "\n",
    "    epochs = 20\n",
    "    print_every = 40\n",
    "    steps = 0\n",
    "\n",
    "    for e in range (epochs): \n",
    "        running_loss = 0\n",
    "        for inputs, labels in iter(trainloaders):\n",
    "            steps += 1\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            #clear up the memory of the optimizer\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #run the model forward\n",
    "            outputs = model.forward(inputs)\n",
    "\n",
    "            #define loss function\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            #backpropagation\n",
    "            loss.backward() \n",
    "\n",
    "            #update the weigth\n",
    "            optimizer.step()\n",
    "\n",
    "            #running total of loss value in scalar format\n",
    "            running_loss += loss.item ()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                #switch to model evaluation model to turn off drop out \n",
    "                model.eval ()\n",
    "\n",
    "                # Turn off gradients for validation\n",
    "                with torch.no_grad():\n",
    "                    model.to (device)\n",
    "                    valid_loss = 0\n",
    "                    accuracy = 0\n",
    "                    for inputs, labels in validloaders:\n",
    "\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        output = model.forward(inputs)\n",
    "                        valid_loss += criterion(output, labels).item()\n",
    "\n",
    "                        ps = torch.exp(output)\n",
    "\n",
    "                        #methhod 1 for accuracy calculation\n",
    "                        #equality = (labels.data == ps.max(dim=1)[1])\n",
    "                        #accuracy += equality.type(torch.FloatTensor).mean()\n",
    "\n",
    "                        #methodl 2 for accuracy calculation\n",
    "                        top_p, top_class = ps.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Valid Loss: {:.3f}.. \".format(valid_loss/len(validloaders)),\n",
    "                      \"Valid Accuracy: {:.3f}%.. \".format(accuracy/len(validloaders)*100),\n",
    "                       \"Valid Accuracy - absolute value: {:.3f}.. \".format(accuracy),\n",
    "                       \"ValidLoaders Length - absolute value: {:.3f}\".format(len(validloaders))\n",
    "\n",
    "                     )\n",
    "\n",
    "                running_loss = 0\n",
    "\n",
    "                # Make sure training is back on\n",
    "                model.train()\n",
    "\n",
    "# # TODO: Do validation on the test set\n",
    "# # Do validation on the test set\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     for data in trainloaders:\n",
    "#         images, labels = data\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy achieved by the network on test images is: %d%%' % (100 * correct / total))                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "def save_checkpoint(model, train_data, optimizer, model_pth_file, epochs):\n",
    "    model.class_to_idx = train_data.class_to_idx\n",
    "    model.to('cpu')\n",
    "    checkpoint = {'model_state_dict': model.state_dict(),\n",
    "              'classifier': model.classifier,\n",
    "              'class_to_idx': train_data.class_to_idx,\n",
    "              'optimizer_state_dict': optimizer.state_dict,\n",
    "              'epochs': epochs}\n",
    "\n",
    "    torch.save(checkpoint, model_pth_file)\n",
    "    \n",
    "def load_checkpoint(model_pth_file,model_type='vgg16'):\n",
    "    \"\"\"\n",
    "    Loads deep learning model checkpoint.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the saved file\n",
    "    checkpoint = torch.load(model_pth_file)\n",
    "    \n",
    "    # Download pretrained model\n",
    "    \n",
    "    arch={'vgg16':25088, 'densenet121': 1024}\n",
    "\n",
    "    if model_type=='vgg16':\n",
    "        model =models.vgg16(pretrained=True)\n",
    "    elif model_type=='densenet121':\n",
    "        model=models.densenet121(pretrained=True)\n",
    "    else:\n",
    "        print(\"the model you choose is not available, please choose vgg16 or densenet121\")\n",
    "     \n",
    "    # Freeze parameters so we don't backprop through them\n",
    "    for param in model.parameters(): \n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Load stuff from checkpoint\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    model.classifier = checkpoint['classifier']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def process_image(image_path):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    image_pil=Image.open(image_path)\n",
    "    transform=transforms.Compose([transforms.Resize(256),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                     [0.229,0.224,0.225])])\n",
    "    \n",
    "    image_tensor=transform(image_pil)\n",
    "    #convert to numpy array\n",
    "    image_ndarray=np.array(image_tensor)\n",
    "    return image_ndarray\n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    \n",
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    import numpy as np\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def predict(image_path, model_pth_file, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    model=load_checkpoint(model_pth_file)\n",
    "    model.to(device)\n",
    "    image_ndarray=process_image(image_path)\n",
    "    image_tensor=torch.from_numpy(image_ndarray).type(torch.FloatTensor)\n",
    "\n",
    "    image_tensor_added_dimension=image_tensor.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        output=model.forward(image_tensor_added_dimension.to(device))\n",
    "    #         probability = F.softmax(output.data, dim=1)\n",
    "\n",
    "        ps = torch.exp(output)\n",
    "\n",
    "        top_p, top_class = ps.topk(5)\n",
    "        \n",
    "        top_p_list=np.array(top_p)[0]\n",
    "        \n",
    "        top_class_list=np.array(top_class)[0]\n",
    "        #loading index and class mapping\n",
    "        class_to_idx=model.class_to_idx\n",
    "        #swap the location of index and class\n",
    "        index_to_class = {x: y for y, x in class_to_idx.items()}\n",
    "        \n",
    "        top_labels=[index_to_class[x] for x in top_class_list]\n",
    "\n",
    "        top_flowers=list(map(cat_to_name.get, top_labels))\n",
    "\n",
    "    return top_p_list, top_flowers\n",
    "#     probability.topk(topk)\n",
    "    # TODO: Implement the code to predict the class from an image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders, validloaders, testloaders = transform_load_image('flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels=next(iter(trainloaders))\n",
    "images.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
